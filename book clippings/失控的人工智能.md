一直以来对人工智能都非常有兴趣，虽然大学和研究生阴差阳错跑去弄计算机图形学了，但是人工智能始终没有放下，课余时间能看一点是一点。失控这本书很有意思，第二章就
提出了某种形式的人工智能思路，让我大呼过瘾。因为复习考试的缘故，我也就只能看完前面一小部分了，不过能写的依然不少，就来说说人工智能吧。

  

其实人工智能是颇为坎坷的一个学科，上个世纪刚刚兴起的时候，就好像现在的云计算和大数据一样，着实火了一把，涌现出了一大批基于规则的专家系统，当时研究人员也相当
乐观，电脑战胜人脑指日可待的节奏。不过正所谓前浪死在沙滩上，想要多快好省弄出一个人工智能体，在经历了十几二十年的尝试无果之后，人工智能的冬天也就到来了。不少
电影和游戏也表达出对人工智能的忧虑与思考，我印象比较深的就是I, Robot了，不过说实在的，按照现在的发展速度，那还真是要到猴年马月了。

  

说人工智能可能太玄乎，我们来说个基础的，文法分析器。学过编译原理的同学对这个肯定不陌生，没学过的话，我简单说一下，就是按照某些已定好的规则，来分析语句的程序
。比方对于“我喜欢你”这句话，那么文法分析器就可以把句子的结构匹配为“主谓宾”，然后交给，后面的语法分析器来操作。所以问题来了，我们能不能说，这个文法分析器
就有人工智能呢？你看它可以识别出不同的句子结构呢！这个问题见仁见智，不过我们可以找图灵大师的评判标准来想想，图灵测试是测试人在与被测试者(一个人和一台机器)
隔开的情况下，通过一些装置（如键盘）向被测试者随意提问。问过一些问题后，如果测试人不能确认被测试者30%的答复哪个是人、哪个是机器的回答，那么这台机器就通过
了测试，并被认为具有人类智能。还没有一台机器能够通过图灵测试。

  

也就是说，从图灵的角度来看，这个文法分析器不具有人类智能。不妨再假设一下，假若这台机器真的能做到回答以假乱真呢？比方说所有的问题都可以比较好的回答，那是不是
就说明它有人类智能？

  

我觉得它还是没有，为什么，再举个例子，在马戏团我们常常可以看到动物作画的表演，比方说大象画一朵花什么之类的，问题在于，大象画花，它并不理解它画的是什么，而只
是重复在训练中习惯的某种形式的线条（如果它能理解线条的话），对于大象来说，画出来的东西虽然在我们看来是花，但是在它看来，就是无意义的线条（请注意前面的假设）
。

  

这样来看通过图灵测试的这台机器，它的回答可能在我们人类看起来是有意义的，但是它本身到底理不理解这个答案的含义呢？我不知道。但是我觉得，目前基于规则和统计的机
器学习方式给出的结果，实际上机器本身是不明白自己回答出来的是什么东西的，它只是给出了可能的最优解。

  

既然已经扯远了，我不妨再扯远一些。本科的毕业设计做的是一个自动问答系统，大概是这样的，你如果输入“中国的首都在哪里”，那么我做的系统会告诉你答案是“北京”。
好，假设我这个系统了解的东西足够多（当然是基于这种有固定事实的问题，如果问的是魔镜魔镜我美不美，那就无能为力了），那么也没有办法证明这个系统到底知不知道自己
给出的答案到底是什么意思。

  

于是我想了一个办法，叫做关系的二阶推导，用这个来测试。大概是这样的意思，比方说我的系统知道中国的首都是北京，同时也知道北京的人口有多少，那么如果我问，中国的
首都有多少人，这个系统应该会自动把这两条答案找出来，然后进行简单的推导，给出答案。显然我的系统做不到，但是其实这也可以做，同样可以基于某种推导的规则，甚至可
以解决更高阶的推导，比方说“谢霆锋的前妻的前夫的前妻的前夫是谁”，有兴趣的可以去百度搜一下，还真能给出答案，甚至有推导的过程。

  

这说明这个问题在某种程度上是可解的，但是还是那个问题，给出答案的百度，真的明白它给出的答案是什么意思吗？

  

所以我觉得最终的解答还要回到失控里提到的，是很多简单的个体，已某种简单的规则组合，在达到一定数量的界限之后，表现出的超越个体的集体的特点，我觉得这才应该是人
工智能的未来。一写就写长了，欢迎大家指教拍砖。

